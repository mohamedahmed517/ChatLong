{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install pip3-autoremove\n!pip-autoremove torch torchvision torchaudio -y\n!pip install azure-ai-textanalytics\n!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu121\n!pip install unsloth","metadata":{"id":"fKuozprj_wKy","execution":{"iopub.status.busy":"2024-11-13T13:18:44.954778Z","iopub.execute_input":"2024-11-13T13:18:44.955182Z","iopub.status.idle":"2024-11-13T13:22:44.247649Z","shell.execute_reply.started":"2024-11-13T13:18:44.955140Z","shell.execute_reply":"2024-11-13T13:22:44.246491Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from azure.core.credentials import AzureKeyCredential\nfrom azure.ai.textanalytics import TextAnalyticsClient\nfrom unsloth.chat_templates import get_chat_template\nfrom unsloth import FastLanguageModel\nimport re","metadata":{"execution":{"iopub.status.busy":"2024-11-13T13:22:44.249735Z","iopub.execute_input":"2024-11-13T13:22:44.250096Z","iopub.status.idle":"2024-11-13T13:23:06.875636Z","shell.execute_reply.started":"2024-11-13T13:22:44.250058Z","shell.execute_reply":"2024-11-13T13:23:06.874617Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"}]},{"cell_type":"code","source":"def classify_text(query):\n    try:\n\n        ai_endpoint = 'https://myclassification51.cognitiveservices.azure.com/'\n        ai_key = '2AguPGY8KcIcngKeVUidX7JxS9DrkKbEvxpkVYatZUGuE0Nab5bbJQQJ99AKACYeBjFXJ3w3AAAaACOGYgZA'\n        project_name = 'ClassifyLab'\n        deployment_name = 'MyDeployment'\n\n        # Create client using endpoint and key\n        credential = AzureKeyCredential(ai_key)\n        ai_client = TextAnalyticsClient(endpoint=ai_endpoint, credential=credential)\n\n        # Prepare the query for classification\n        batchedDocuments = [query]\n\n        # Get Classification\n        operation = ai_client.begin_single_label_classify(\n            batchedDocuments,\n            project_name=project_name,\n            deployment_name=deployment_name\n        )\n\n        document_results = operation.result()\n\n        # Extract classification result\n        for classification_result in document_results:\n            if classification_result.kind == \"CustomDocumentClassification\":\n                classification = classification_result.classifications[0]\n                return classification.category, classification.confidence_score\n            elif classification_result.is_error:\n                return None, classification_result.error.message\n\n    except Exception as ex:\n        return None, str(ex)","metadata":{"id":"8_NR3R2O_3u_","execution":{"iopub.status.busy":"2024-11-13T13:23:06.888646Z","iopub.execute_input":"2024-11-13T13:23:06.889064Z","iopub.status.idle":"2024-11-13T13:23:06.927770Z","shell.execute_reply.started":"2024-11-13T13:23:06.889019Z","shell.execute_reply":"2024-11-13T13:23:06.926778Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model, tokenizer = FastLanguageModel.from_pretrained(\"mohamed517/Arabic-fine-Tuning-LLaMA-Model\")","metadata":{"execution":{"iopub.status.busy":"2024-11-13T13:23:27.088425Z","iopub.execute_input":"2024-11-13T13:23:27.089467Z","iopub.status.idle":"2024-11-13T13:24:01.469515Z","shell.execute_reply.started":"2024-11-13T13:23:27.089410Z","shell.execute_reply":"2024-11-13T13:24:01.468591Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2024.11.6: Fast Llama patching. Transformers = 4.46.2.\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\nO^O/ \\_/ \\    Pytorch: 2.5.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be530ebb5a5c4c99863db5450ef33360"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/220 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58c0d2c1e8f64e34908fb416aebfdf22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/51.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"725b1ec7bcb44d439bea265f34c185b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f06e4089fcab4209a9923f8cc73111aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/345 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"667b67211afb48eabd4de838a925ff32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b826da9a0b1a4453af24ebe5dc40fcf4"}},"metadata":{}},{"name":"stderr","text":"Unsloth 2024.11.6 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = get_chat_template(\n    tokenizer,\n    chat_template = \"llama-3\", # Supports zephyr, chatml, mistral, llama, alpaca, vicuna, vicuna_old, unsloth\n    mapping = {\"role\" : \"from\", \"content\" : \"value\", \"user\" : \"human\", \"assistant\" : \"gpt\"}, # ShareGPT style\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-13T13:24:05.999883Z","iopub.execute_input":"2024-11-13T13:24:06.000381Z","iopub.status.idle":"2024-11-13T13:24:06.006968Z","shell.execute_reply.started":"2024-11-13T13:24:06.000335Z","shell.execute_reply":"2024-11-13T13:24:06.005799Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def generation(question):\n\n    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n\n    category, confidence_score = classify_text(question)\n\n    context = f\"انت معالج بالذكاء الاصطناعي قيد التدريب ومهمتك هي تقديم دعم عاطفي مدروس ومخصص لكل مستخدم بناء علي حالته النفسيه الحاليه ستقوم بالاستماع بعنايه الي مخاوفهم ومشاعرهم مع مراعاه ان الحاله النفسيه للمريض هي {category} قم بتقديم استجابات ملاءمه للوضع الذي يمر به استخدم معرفتك بمختلف المناهج العلاجيه لتقديم تقنيات ومحادثات داعمه بلهجه ودوده ومتفهمه تذكر انك مورد للدعم العاطفي والارشاد ولست بديلا عن المعالج البشري تعامل مع المريض بصدق واحترام وكن مرنا في محادثاتك لتتناسب مع حالته النفسيه وحاول التخفيف عنه بطريقه لطيفه ومتوازنه\"\n\n    # Create the messages list with the context and user input\n    messages = [\n        {\"from\": \"system\", \"value\": context},\n        {\"from\": \"human\", \"value\": question},\n    ]\n\n    inputs = tokenizer.apply_chat_template(\n        messages,\n        tokenize = True,\n        add_generation_prompt = True, # Must add for generation\n        return_tensors = \"pt\",\n    ).to(\"cuda\")\n\n    outputs = model.generate(input_ids = inputs, max_new_tokens = 400, use_cache = True)\n    model_answer = tokenizer.batch_decode(outputs)\n\n    return model_answer","metadata":{"id":"_eSFpXg5AGBe","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6b97a024-e72e-426e-b6be-cd6789c0ba71","execution":{"iopub.status.busy":"2024-11-13T13:24:09.533882Z","iopub.execute_input":"2024-11-13T13:24:09.534914Z","iopub.status.idle":"2024-11-13T13:24:09.542803Z","shell.execute_reply.started":"2024-11-13T13:24:09.534867Z","shell.execute_reply":"2024-11-13T13:24:09.541710Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def adjustPattern(model_answer):\n    \n    # Assuming model_answer is a list with the model's output string at the first index\n    model_answer_str = model_answer[0]\n\n    # Adjusted regex pattern to capture all relevant sections\n    pattern = re.compile(r'<\\|start_header_id\\|>(.*?)<\\|end_header_id\\|>(.*?)<\\|eot_id\\|>', re.DOTALL)\n\n    # Find all matches and store them in a structured format\n    sections = pattern.findall(model_answer_str)\n    output = {\"user\": [], \"bot\": []}\n\n    for role, content in sections:\n        role = role.strip().lower()  # Normalize the role for comparison\n        content = content.strip()  # Clean up the content\n        if role == 'system':\n            continue  # Skip the system role\n        elif role == 'user':\n            output[\"user\"].append(content)\n        elif role == 'assistant':\n            output[\"bot\"].append(content)\n\n    # Check for any direct assistant response after the user's input if not captured above\n    if 'assistant' not in [role.strip().lower() for role, _ in sections]:\n        assistant_start_index = model_answer_str.find('<|start_header_id|>assistant<|end_header_id|>')\n        if assistant_start_index != -1:\n            assistant_content = model_answer_str[assistant_start_index:].split('<|eot_id|>')[0]\n            output[\"bot\"].append(\n                assistant_content.replace('<|start_header_id|>', '').replace('<|end_header_id|>', '').strip()\n            )\n    \n    return output","metadata":{"id":"a0zVj3xoBqGX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f56ba1b0-90c4-4588-ed7e-c97eb2d5ecde","execution":{"iopub.status.busy":"2024-11-13T13:24:13.028423Z","iopub.execute_input":"2024-11-13T13:24:13.029114Z","iopub.status.idle":"2024-11-13T13:24:13.038733Z","shell.execute_reply.started":"2024-11-13T13:24:13.029068Z","shell.execute_reply":"2024-11-13T13:24:13.037743Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"question = \"علي طول مضايقه ونفسيتي تعبانه وبس ابكي ما ابغي اقابل احد وعلي طول اخاصم اطفالي واصرخ عليهم واروح الغرفه لوحدي مع العلم انه في الليل ازعل علي تصرفاتي فما الحل\"\n\nmodel_answer = generation(question)","metadata":{"execution":{"iopub.status.busy":"2024-11-13T13:41:38.296066Z","iopub.execute_input":"2024-11-13T13:41:38.296522Z","iopub.status.idle":"2024-11-13T13:41:47.964041Z","shell.execute_reply.started":"2024-11-13T13:41:38.296479Z","shell.execute_reply":"2024-11-13T13:41:47.963132Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Call the function\nparsed_output = adjustPattern(model_answer)\n\n# Access and print each role's content\nfor role, contents in parsed_output.items():\n    print(f\"{role.capitalize()} response:\")\n    for content in contents:\n        print(f\"\\n{content}\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-11-13T13:41:52.403776Z","iopub.execute_input":"2024-11-13T13:41:52.404195Z","iopub.status.idle":"2024-11-13T13:41:52.410131Z","shell.execute_reply.started":"2024-11-13T13:41:52.404154Z","shell.execute_reply":"2024-11-13T13:41:52.409195Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"User response:\n\nعلي طول مضايقه ونفسيتي تعبانه وبس ابكي ما ابغي اقابل احد وعلي طول اخاصم اطفالي واصرخ عليهم واروح الغرفه لوحدي مع العلم انه في الليل ازعل علي تصرفاتي فما الحل\n\nBot response:\n\nالطول النفسي والجسدي يحتاجان الي تقيم طبي لمعرفه الحاله النفسيه بشكل دقيق وبالتاكيد يحتاج الي علاج نفسي مكثف ومخصص لكل حاله\n\n","output_type":"stream"}]}]}